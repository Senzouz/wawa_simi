{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexPP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORojqERY09EX"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5QQhskB1Bbj"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNFkWAH21DaB"
      },
      "source": [
        "fid = drive.ListFile({'q':\"title='VC Mal Pronunciadas.zip'\"}).GetList()[0]['id']\n",
        "m = drive.CreateFile({'id': fid})\n",
        "m.GetContentFile('data.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qbA-mk01MCu"
      },
      "source": [
        "!unzip data.zip -d ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TODsKwR1MH-"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import skimage.io\n",
        "from skimage.transform import resize\n",
        "from skimage import img_as_ubyte\n",
        "from skimage.color import gray2rgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV0-u2hv1RkN"
      },
      "source": [
        "def scale_minmax(X, min=0.0, max=1.0):\n",
        "    X_std = (X - X.min()) / (X.max() - X.min())\n",
        "    X_scaled = X_std * (max - min) + min\n",
        "    return X_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b50Xl1f71TpP"
      },
      "source": [
        "def spectrogram_image(y, sr):\n",
        "    mels = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    #mels = np.log(mels + 1e-9)\n",
        "\n",
        "    img = scale_minmax(mels, 0, 255).astype(np.uint8)\n",
        "    img = np.flip(img, axis=0)\n",
        "    img = 255-img\n",
        "\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujMnP17H1VpN"
      },
      "source": [
        "specgrams = []\n",
        "specgrams2 = []\n",
        "\n",
        "archivos = os.listdir('VC Mal Pronunciadas')\n",
        "for audio in archivos:\n",
        "  array = audio.split('_')\n",
        "  temp = audio[:8]\n",
        "  if audio.endswith('.wav') and array[2] != 'RR':\n",
        "    y, sr = librosa.load('VC Mal Pronunciadas/' + audio)\n",
        "    image = spectrogram_image(y, sr)\n",
        "    image_resized = resize(image, (224, 224), anti_aliasing=True)\n",
        "    if temp in lista_test:\n",
        "      if audio.endswith('bubanda.wav') or audio.endswith('platamo.wav') or audio.endswith('madiposa.wav') or audio.endswith('gufanda.wav') or audio.endswith('lilicoptero.wav'):\n",
        "        specgrams2.append([image_resized, 1])\n",
        "      elif audio.endswith('ficio.wav') or audio.endswith('fisio.wav') or audio.endswith('buante.wav') or audio.endswith('poca.wav') or audio.endswith('marifosa.wav') or audio.endswith('tien.wav'):\n",
        "        specgrams2.append([image_resized, 2])\n",
        "      else:\n",
        "        specgrams2.append([image_resized, 0])\n",
        "    else:\n",
        "      if audio.endswith('bubanda.wav') or audio.endswith('platamo.wav') or audio.endswith('madiposa.wav') or audio.endswith('gufanda.wav') or audio.endswith('lilicoptero.wav'):\n",
        "        specgrams.append([image_resized, 1])\n",
        "      elif audio.endswith('ficio.wav') or audio.endswith('fisio.wav') or audio.endswith('buante.wav') or audio.endswith('poca.wav') or audio.endswith('marifosa.wav') or audio.endswith('tien.wav'):\n",
        "        specgrams.append([image_resized, 2])\n",
        "      else:\n",
        "        specgrams.append([image_resized, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN6dX-iTScKb"
      },
      "source": [
        "specgrams = []\n",
        "archivos = os.listdir('VC Mal Pronunciadas')\n",
        "archivos.sort()\n",
        "for audio in archivos:\n",
        "  array = audio.split('_')\n",
        "  temp = audio[:8]\n",
        "  if audio.endswith('.wav') and array[2] != 'RR':\n",
        "    y, sr = librosa.load('VC Mal Pronunciadas/' + audio)\n",
        "    image = spectrogram_image(y, sr)\n",
        "    image_resized = resize(image, (224, 224), anti_aliasing=True)\n",
        "    if audio.endswith('bubanda.wav') or audio.endswith('platamo.wav') or audio.endswith('madiposa.wav') or audio.endswith('gufanda.wav') or audio.endswith('lilicoptero.wav'):\n",
        "        specgrams.append([image_resized, 1])\n",
        "    elif audio.endswith('ficio.wav') or audio.endswith('fisio.wav') or audio.endswith('buante.wav') or audio.endswith('poca.wav') or audio.endswith('marifosa.wav') or audio.endswith('tien.wav'):\n",
        "        specgrams.append([image_resized, 2])\n",
        "    else:\n",
        "        specgrams.append([image_resized, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjsDpR6-Sf4j"
      },
      "source": [
        "df = pd.DataFrame(specgrams)\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FUiJK7lShCm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test = train_test_split(df, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8cOXbfX8pol"
      },
      "source": [
        "df = pd.DataFrame(specgrams)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df2 = pd.DataFrame(specgrams2)\n",
        "df2 = df2.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrJLCbe88tmt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMUlez2o8vZ5",
        "outputId": "541f1862-5aaa-43d5-c0ba-0c88d0c17b28"
      },
      "source": [
        "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
        "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "\n",
        "#Descripción del modelo\n",
        "AlexNet_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVhVENS58y2B"
      },
      "source": [
        "#Modificación de la primera capa convolucional\n",
        "AlexNet_model.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "\n",
        "#Modificación de la penultima capa completamente conectada\n",
        "AlexNet_model.classifier[4] = nn.Linear(4096,1024)\n",
        "\n",
        "#Modificación de la última capa completamente conectada\n",
        "AlexNet_model.classifier[6] = nn.Linear(1024,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRXDJT5183Vu",
        "outputId": "d86453ae-93b3-41d8-a25a-603e7ef84be4"
      },
      "source": [
        "#Creación de instancia del dispositivo CUDA\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Verificando si CUDA esta disponible\n",
        "print(device)\n",
        "\n",
        "#Si CUDA está disponible, se traslada el modelo a este dispositivo\n",
        "AlexNet_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=1024, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ2kVywD87a6"
      },
      "source": [
        "def toDataLoader(data):\n",
        "  input = torch.tensor(list(data[0].to_numpy()))\n",
        "  target = torch.tensor(list(data[1])).type(torch.LongTensor)\n",
        "  tensor = data_utils.TensorDataset(input, target) \n",
        "  loader = data_utils.DataLoader(dataset = tensor, batch_size=4, shuffle=True, num_workers=2)\n",
        "  return loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_MQmIuY89XA"
      },
      "source": [
        "#Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Optimizer(SGD)\n",
        "optimizer = optim.Adam(AlexNet_model.parameters(), lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-D5Gbrk8-0X",
        "outputId": "45a5ec33-57cd-4349-f2a2-d99f983239b7"
      },
      "source": [
        "#train_loader = toDataLoader(x_train)\n",
        "\n",
        "for epoch in range(30):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # obtener los inputs; \"data\" es una lista de [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = inputs.unsqueeze(1)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        output = AlexNet_model(inputs.float())\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # imprimir estadísticas\n",
        "        running_loss += loss.item()\n",
        "        if i % 150 == 149:\n",
        "            print('[%d, %5d] loss: %d - %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss, running_loss / 150))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training of AlexNet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   150] loss: 153 - 1.025\n",
            "[1,   300] loss: 148 - 0.993\n",
            "[2,   150] loss: 142 - 0.953\n",
            "[2,   300] loss: 137 - 0.914\n",
            "[3,   150] loss: 121 - 0.809\n",
            "[3,   300] loss: 117 - 0.785\n",
            "[4,   150] loss: 103 - 0.689\n",
            "[4,   300] loss: 97 - 0.650\n",
            "[5,   150] loss: 91 - 0.610\n",
            "[5,   300] loss: 88 - 0.589\n",
            "[6,   150] loss: 77 - 0.518\n",
            "[6,   300] loss: 77 - 0.516\n",
            "[7,   150] loss: 71 - 0.475\n",
            "[7,   300] loss: 69 - 0.464\n",
            "[8,   150] loss: 61 - 0.409\n",
            "[8,   300] loss: 66 - 0.444\n",
            "[9,   150] loss: 56 - 0.377\n",
            "[9,   300] loss: 52 - 0.347\n",
            "[10,   150] loss: 51 - 0.343\n",
            "[10,   300] loss: 47 - 0.317\n",
            "[11,   150] loss: 40 - 0.269\n",
            "[11,   300] loss: 42 - 0.286\n",
            "[12,   150] loss: 40 - 0.272\n",
            "[12,   300] loss: 35 - 0.238\n",
            "[13,   150] loss: 33 - 0.223\n",
            "[13,   300] loss: 35 - 0.239\n",
            "[14,   150] loss: 26 - 0.175\n",
            "[14,   300] loss: 29 - 0.197\n",
            "[15,   150] loss: 26 - 0.175\n",
            "[15,   300] loss: 19 - 0.127\n",
            "[16,   150] loss: 23 - 0.159\n",
            "[16,   300] loss: 17 - 0.116\n",
            "[17,   150] loss: 14 - 0.095\n",
            "[17,   300] loss: 17 - 0.115\n",
            "[18,   150] loss: 13 - 0.091\n",
            "[18,   300] loss: 14 - 0.096\n",
            "[19,   150] loss: 10 - 0.069\n",
            "[19,   300] loss: 14 - 0.096\n",
            "[20,   150] loss: 7 - 0.053\n",
            "[20,   300] loss: 11 - 0.079\n",
            "[21,   150] loss: 8 - 0.055\n",
            "[21,   300] loss: 7 - 0.048\n",
            "[22,   150] loss: 6 - 0.045\n",
            "[22,   300] loss: 5 - 0.039\n",
            "[23,   150] loss: 4 - 0.029\n",
            "[23,   300] loss: 7 - 0.052\n",
            "[24,   150] loss: 17 - 0.119\n",
            "[24,   300] loss: 3 - 0.026\n",
            "[25,   150] loss: 4 - 0.031\n",
            "[25,   300] loss: 7 - 0.049\n",
            "[26,   150] loss: 2 - 0.017\n",
            "[26,   300] loss: 3 - 0.022\n",
            "[27,   150] loss: 1 - 0.013\n",
            "[27,   300] loss: 2 - 0.017\n",
            "[28,   150] loss: 1 - 0.010\n",
            "[28,   300] loss: 1 - 0.008\n",
            "[29,   150] loss: 0 - 0.006\n",
            "[29,   300] loss: 0 - 0.006\n",
            "[30,   150] loss: 0 - 0.005\n",
            "[30,   300] loss: 1 - 0.007\n",
            "Finished Training of AlexNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN3nqDxQHBeA"
      },
      "source": [
        "def calculateConfusionMatrix(predicted, true):\n",
        "  for i in range (3):\n",
        "    if predicted == true and predicted == i:\n",
        "      TP[i] += 1\n",
        "    elif predicted == true:\n",
        "      TN[i] += 1\n",
        "    elif predicted != true and predicted == i:\n",
        "      FP[i] += 1\n",
        "    elif predicted != true:\n",
        "      FN[i] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rCmdmQ2GXCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbb53bd-cecd-4be9-87fc-8aab9179a900"
      },
      "source": [
        "#test_loader = toDataLoader(x_test)\n",
        "\n",
        "#Testing Accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "TP = [0 for fila in range (0,3)]\n",
        "TN = [0 for fila in range (0,3)]\n",
        "FN = [0 for fila in range (0,3)]\n",
        "FP = [0 for fila in range (0,3)]\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    images = images.unsqueeze(1)\n",
        "    outputs = AlexNet_model(images.float())\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "    for j in range(len(predicted)):\n",
        "      calculateConfusionMatrix(predicted[j], labels[j])\n",
        "\n",
        "print('Accuracy test: %d%%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy test: 99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzk4-YkcHyhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db3526e-61eb-4862-901a-4fff3cafd84f"
      },
      "source": [
        "for i in range(len(TP)):\n",
        "  print('Class %d' % i)\n",
        "  print('%d\\t%d' % (TP[i], FN[i]))\n",
        "  print('%d\\t%d' % (FP[i], TN[i]))\n",
        "  print('Accuracy: %d%%' % (100 * (TP[i] + TN[i]) / (TP[i] + TN[i] + FN[i] + FP[i])))\n",
        "  print('Precision: %d%%' % (100 * TP[i] / (TP[i] + FP[i])))\n",
        "  print('Recall: %d%%' % (100 * TP[i] / (TP[i] + FN[i])))\n",
        "  print('------------------------------')\n",
        "  print('------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0\n",
            "305\t5\n",
            "0\t243\n",
            "Accuracy: 99%\n",
            "Precision: 100%\n",
            "Recall: 98%\n",
            "------------------------------\n",
            "------------------------------\n",
            "Class 1\n",
            "126\t1\n",
            "4\t422\n",
            "Accuracy: 99%\n",
            "Precision: 96%\n",
            "Recall: 99%\n",
            "------------------------------\n",
            "------------------------------\n",
            "Class 2\n",
            "117\t4\n",
            "1\t431\n",
            "Accuracy: 99%\n",
            "Precision: 99%\n",
            "Recall: 96%\n",
            "------------------------------\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLt8CRv030f"
      },
      "source": [
        "torch.save(AlexNet_model, 'AlexNet_PP_30.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMffzTJJLH5Y"
      },
      "source": [
        "#Prueba 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ01KjavL5pz",
        "outputId": "b25afff5-1491-4fa4-a86a-5f7bfbe2a50d"
      },
      "source": [
        "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
        "AlexNet_model1 = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "\n",
        "#Descripción del modelo\n",
        "AlexNet_model1.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4YuF_YiMB15"
      },
      "source": [
        "#Modificación de la primera capa convolucional\n",
        "AlexNet_model1.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "\n",
        "#Modificación de la penultima capa completamente conectada\n",
        "AlexNet_model1.classifier[4] = nn.Linear(4096,1024)\n",
        "\n",
        "#Modificación de la última capa completamente conectada\n",
        "AlexNet_model1.classifier[6] = nn.Linear(1024,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFDvtUkQMElc",
        "outputId": "74b2621c-ae21-4a1b-df7c-bcbfff3f7856"
      },
      "source": [
        "#Creación de instancia del dispositivo CUDA\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Verificando si CUDA esta disponible\n",
        "print(device)\n",
        "\n",
        "#Si CUDA está disponible, se traslada el modelo a este dispositivo\n",
        "AlexNet_model1.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=1024, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrjE9kSWMIl7"
      },
      "source": [
        "#Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Optimizer(SGD)\n",
        "optimizer = optim.SGD(AlexNet_model1.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7xdWkGYippd",
        "outputId": "175cf7a0-d2e3-420f-c0bc-bc809d05c282"
      },
      "source": [
        "for epoch in range(15):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # obtener los inputs; \"data\" es una lista de [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = inputs.unsqueeze(1)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        output = AlexNet_model1(inputs.float())\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # imprimir estadísticas\n",
        "        running_loss += loss.item()\n",
        "        if i % 150 == 149:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 150))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training of AlexNet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   150] loss: 1.036\n",
            "[1,   300] loss: 1.014\n",
            "[2,   150] loss: 1.024\n",
            "[2,   300] loss: 0.993\n",
            "[3,   150] loss: 0.954\n",
            "[3,   300] loss: 0.903\n",
            "[4,   150] loss: 0.884\n",
            "[4,   300] loss: 0.868\n",
            "[5,   150] loss: 0.841\n",
            "[5,   300] loss: 0.815\n",
            "[6,   150] loss: 0.726\n",
            "[6,   300] loss: 0.721\n",
            "[7,   150] loss: 0.663\n",
            "[7,   300] loss: 0.541\n",
            "[8,   150] loss: 0.379\n",
            "[8,   300] loss: 0.320\n",
            "[9,   150] loss: 0.223\n",
            "[9,   300] loss: 0.149\n",
            "[10,   150] loss: 0.134\n",
            "[10,   300] loss: 0.170\n",
            "[11,   150] loss: 0.143\n",
            "[11,   300] loss: 0.075\n",
            "[12,   150] loss: 0.103\n",
            "[12,   300] loss: 0.038\n",
            "[13,   150] loss: 0.002\n",
            "[13,   300] loss: 0.001\n",
            "[14,   150] loss: 0.001\n",
            "[14,   300] loss: 0.000\n",
            "[15,   150] loss: 0.000\n",
            "[15,   300] loss: 0.000\n",
            "Finished Training of AlexNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf3Y-BtSzoBA",
        "outputId": "b4fe9444-a657-47c3-b3e6-0f4fb47fc2ca"
      },
      "source": [
        "#Testing Accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "TP = [0 for fila in range (0,3)]\n",
        "TN = [0 for fila in range (0,3)]\n",
        "FN = [0 for fila in range (0,3)]\n",
        "FP = [0 for fila in range (0,3)]\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    images = images.unsqueeze(1)\n",
        "    outputs = AlexNet_model1(images.float())\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "    for j in range(len(predicted)):\n",
        "      if labels[j] == 0:\n",
        "        calculateConfusionMatrix(0, predicted[j], labels[j], 0, 1, 2)\n",
        "      elif labels[j] == 1:\n",
        "        calculateConfusionMatrix(1, predicted[j], labels[j], 1, 0, 2)\n",
        "      elif labels[j] == 2:\n",
        "        calculateConfusionMatrix(2, predicted[j], labels[j], 2, 0, 1)  \n",
        "\n",
        "print('Accuracy test: %d%%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy test: 85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnodEv_5z0RL",
        "outputId": "b0d0ed22-0b4c-4cc0-fa05-42b9af6aed66"
      },
      "source": [
        "for i in range(len(TP)):\n",
        "  print('Class %d' % i)\n",
        "  print('%d\\t%d' % (TP[i], FN[i]))\n",
        "  print('%d\\t%d' % (FP[i], TN[i]))\n",
        "  print('Accuracy test class %d: %d%%' % (i, 100 *(TP[i] + TN[i]) / (TP[i] + TN[i] + FN[i] + FP[i])))\n",
        "  print('Precision test calss %d: %d%%' % (i, 100 * TP[i] / (TP[i] + FP[i])))\n",
        "  print('Recall test class %d: %d%%' % (i, 100 * TP[i] / (TP[i] + FN[i])))\n",
        "  print('------------------------------')\n",
        "  print('------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0\n",
            "270\t24\n",
            "0\t0\n",
            "Accuracy test class 0: 91%\n",
            "Precision test calss 0: 100%\n",
            "Recall test class 0: 91%\n",
            "------------------------------\n",
            "------------------------------\n",
            "Class 1\n",
            "92\t22\n",
            "0\t0\n",
            "Accuracy test class 1: 80%\n",
            "Precision test calss 1: 100%\n",
            "Recall test class 1: 80%\n",
            "------------------------------\n",
            "------------------------------\n",
            "Class 2\n",
            "89\t31\n",
            "0\t0\n",
            "Accuracy test class 2: 74%\n",
            "Precision test calss 2: 100%\n",
            "Recall test class 2: 74%\n",
            "------------------------------\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}